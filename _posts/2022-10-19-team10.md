---
layout: post
comments: true
title: The exploration of policy dissection
author: Ruikang Wu and Mengyuan Zhang (Team 10)
date: 2022-10-19
---

> In many complex tasks, RL-trained policy may not solve the tasks efficiently. The training process may cost people too much time. Policy dissection is a frequency-based method, which can convert RL-trained policy into target-conditioned policy. For this method, we can interacte with the kinematic behavior and the learned neural controller.


<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction
This article will refer to the [source code](https://github.com/metadriverse/policydissect) .

First of all, we want to explore the relationship between kinematic behavior and the neural activities. In this experiment, we want to figure out the patterns behind some certain behaviors. 

Second, we want to train bipedal robots,Cassie, in [IsaacGym](https://github.com/NVIDIA-Omniverse/IsaacGymEnvs), based on the patterns that we figured out. The robots will be trained to have some complex behaviors such as crouch, turn left, turn right, back flip, tiptoe, jump etc. 

Third, we want to explore whether the bipedal robots can handle more complex situtions within the human instruction.

Fourth, we want to explore whether we can improve the algoirthm. For improving the algorithm, we may potentially compare the policy based, value-based and model based methods, and choose the best performance methods.

Finally, we will try to figure out whther we can implement the policy dissection to the other complex tasks in the real world. We are still working on finding the real world problems. 

## Policy Dissection
- What is the Policy Dissection?

    Previous reinforcement learning methods have attempted to design goals-conditioned policies that can achieve human goals, but at the cost of redesigning reward functions and training paradigms. Hence the Policy Dissection, an approach inspired by neuroscience methods based on the primate motor cortex. Using this approach, manually controllable policies can be derived in trained reinforcement learning agents. Experiments show that under the blessing of Policy Dissection, the motion robot exhibits a variety of controllable motor skills.

- Workflow of Policy Dissection

    ![workflow]({{ '/assets/images/team10/algorithm.png' }})
    {: style="width: 400px; max-width: 100%;"}
    *Fig 1. workflow of Policy Dissection* [1].


## Potential Environment
- [IsaacGym](https://github.com/NVIDIA-Omniverse/IsaacGymEnvs) in Python

## Reference
[1] Q. Li, Z. Peng, H. Wu, L. Feng, and B. Zhou. Human-AI shared control via policy dissection. *arXiv preprint arXiv:2206.00152*, 2022. 

[2] D. Bau, J.-Y. Zhu, H. Strobelt, A. Lapedriza, B. Zhou, and A. Torralba. Understanding the role of individual
units in a deep neural network. *Proceedings of the National Academy of Sciences*, 117(48):30071–30078, 2020.

[3] S. Guo, R. Zhang, B. Liu, Y. Zhu, D. Ballard, M. Hayhoe, and P. Stone. Machine versus human attention
in deep reinforcement learning tasks. *Advances in Neural Information Processing Systems*, 34, 2021.

[4] B. Zhou, D. Bau, A. Oliva, and A. Torralba. Interpreting deep visual representations via network dissection. *IEEE transactions on pattern analysis and machine intelligence*, 41(9):2131–2145, 2018.